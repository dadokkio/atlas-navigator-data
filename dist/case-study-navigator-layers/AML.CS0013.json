{
    "versions": {
        "layer": "4.3",
        "navigator": "4.6.4"
    },
    "domain": "atlas-atlas",
    "metadata": [
        {
            "name": "url",
            "value": "https://atlas.mitre.org/studies/AML.CS0013"
        },
        {
            "name": "atlas_data_version",
            "value": "4.8.0"
        }
    ],
    "name": "Backdoor Attack on Deep Learning Models in Mobile Apps",
    "description": "Deep learning models are increasingly used in mobile applications as critical components.\nResearchers from Microsoft Research demonstrated that many deep learning models deployed in mobile apps are vulnerable to backdoor attacks via \"neural payload injection.\"\nThey conducted an empirical study on real-world mobile deep learning apps collected from Google Play. They identified 54 apps that were vulnerable to attack, including popular security and safety critical applications used for cash recognition, parental control, face authentication, and financial services.",
    "techniques": [
        {
            "techniqueID": "AML.T0004",
            "showSubtechniques": false,
            "tactic": "reconnaissance",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0002.001",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0002",
            "showSubtechniques": true,
            "tactic": "resource-development"
        },
        {
            "techniqueID": "AML.T0044",
            "showSubtechniques": false,
            "tactic": "ml-model-access",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0017.000",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0017",
            "showSubtechniques": true,
            "tactic": "resource-development"
        },
        {
            "techniqueID": "AML.T0018.001",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0018",
            "showSubtechniques": true,
            "tactic": "persistence"
        },
        {
            "techniqueID": "AML.T0042",
            "showSubtechniques": false,
            "tactic": "ml-attack-staging",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0010.003",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0010",
            "showSubtechniques": true,
            "tactic": "initial-access"
        },
        {
            "techniqueID": "AML.T0043.004",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0043",
            "showSubtechniques": true,
            "tactic": "ml-attack-staging"
        },
        {
            "techniqueID": "AML.T0041",
            "showSubtechniques": false,
            "tactic": "ml-model-access",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0015",
            "showSubtechniques": false,
            "tactic": "impact",
            "color": "#C8E6C9"
        }
    ],
    "legendItems": [
        {
            "label": "Used in case study",
            "color": "#C8E6C9"
        }
    ]
}